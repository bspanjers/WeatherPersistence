{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d8d7b1-338a-4c3e-8703-a9c7aed46e2f",
   "metadata": {},
   "source": [
    "# This notebook shows how to generate the weather station data for plots 1 and 5\n",
    "##### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8edf94dc-0930-4338-98db-e41e2b2605ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from QAR_persistence_precip import QAR_precipitation\n",
    "from statsmodels.tools.sm_exceptions import PerfectSeparationError\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ebab4c-692f-45b5-bf49-9e925f995282",
   "metadata": {},
   "source": [
    "### Define some functions that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1084020-2d1e-40e5-af06-b7e88e6b5031",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_climate_data(file_path):\n",
    "    # Initialize variables\n",
    "    station_name = None\n",
    "    starting_date = None\n",
    "    \n",
    "    # Open the file for reading\n",
    "    with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "        # Read the file line by line\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove leading and trailing whitespace\n",
    "            if line.startswith(\"This is the blended series of station\"):\n",
    "                station_info = line.split(\"(\")\n",
    "                if len(station_info) > 1:\n",
    "                    station_name = station_info[1].split(\")\")[0].split(\",\")[-1].strip()[7:]\n",
    "                break  # Exit the loop after finding station info\n",
    "\n",
    "        # Open the file again for reading\n",
    "        # Skip the header lines\n",
    "        for line in file:\n",
    "            if line.startswith(\"STAID\"):\n",
    "                break\n",
    "        \n",
    "        # Read the first observation to get the starting date\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                data = line.split(\",\")\n",
    "                starting_date = data[2][:4]  # Extract the year part of the date\n",
    "                break  # Exit the loop after finding starting date\n",
    "\n",
    "    return station_name, starting_date\n",
    "\n",
    "def map_station_with_city(station_name, file_name):\n",
    "    # Open the file for reading\n",
    "    with open(file_name, 'r', encoding='ISO-8859-1') as file:\n",
    "        # Skip the header lines\n",
    "        next(file)\n",
    "        next(file)\n",
    "\n",
    "        # Read the file line by line\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove leading and trailing whitespace\n",
    "            if line:\n",
    "                # Extract station information\n",
    "                station_data = line.split(\",\")\n",
    "                if len(station_data) >= 5:  # Ensure there are enough elements in the list\n",
    "                    current_station_name = station_data[0].strip()\n",
    "                    if current_station_name == station_name:\n",
    "                        city_name = station_data[1].strip()\n",
    "                        latitude = station_data[3].strip()\n",
    "                        longitude = station_data[4].strip()\n",
    "                        return city_name, latitude, longitude\n",
    "\n",
    "    return None, None, None  # Return None if station not found\n",
    "\n",
    "\n",
    "# Define function to assign seasons\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'summer'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'autumn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f336a102-66f5-408a-90bb-3ccdd311f03b",
   "metadata": {},
   "source": [
    "## Generate data for Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "726e7cec-4bbc-4bf5-accf-a2d0ff9b72e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently calculating station 8330 out of 8330"
     ]
    }
   ],
   "source": [
    "\n",
    "#load only those stations that are used in Fig 5 as well\n",
    "start_date = 1950\n",
    "start_year_old = start_date\n",
    "end_year_old = start_date + 30\n",
    "start_year_new = 1990\n",
    "end_year_new = start_year_new + 30\n",
    "drop_na_larger_than = 0.05\n",
    "\n",
    "\n",
    "folder_path = '../data_persistence/ECA_blend_rr/'\n",
    "lendata = len(np.sort(os.listdir(folder_path))[:-4])\n",
    "lat_long = pd.DataFrame(np.zeros((lendata, 5)))\n",
    "lat_long[:] = np.nan\n",
    "for (i, file_name) in enumerate(np.sort(os.listdir(folder_path))[1:-4]):\n",
    "    station_name, starting_date = read_climate_data(folder_path + file_name)\n",
    "    city_name, latitude, longitude = map_station_with_city(station_name, folder_path + 'stations.txt')\n",
    "    if type(starting_date) != type(None):\n",
    "        if int(starting_date) <= start_date:\n",
    "                lat_long.iloc[i,:] = [file_name, station_name, latitude, longitude, city_name]\n",
    "\n",
    "# now for the selected stations calculate the statistics for dec 23-feb 24 \n",
    "start_date = 2020\n",
    "start_year_old = start_date\n",
    "end_year_old = start_date + 30\n",
    "start_year_new = 2023\n",
    "end_year_new = start_year_new + 35\n",
    "drop_na_larger_than = 0.05\n",
    "\n",
    "df = lat_long.dropna()  \n",
    "df.columns =  ['file_name', 'STAID', 'latitude', 'longitude', 'city_name']\n",
    "df_results = pd.DataFrame(np.zeros((len(df), 12)), columns=['STANAME', 'STAID', 'latitude', 'longitude', \n",
    "                                                            'maxStreak', 'rain_acc', 'percentage_rainy_days_upperquintile', 'percentage_rainy_days_NAOplus', \\\n",
    "                                                                'nao_upper_quintile_acc', 'nao_pos_acc', 'total_precip_acc', 'percentage_rainy_days_total'])\n",
    "df_results[:] = np.nan\n",
    "for (i, file_name) in enumerate(df.file_name):\n",
    "    print(f'\\rCurrently calculating station {i+1} out of {len(df.file_name)}', end='')\n",
    "    \n",
    "    try:\n",
    "        test = QAR_precipitation(sFile=file_name, dropna=drop_na_larger_than,\n",
    "                       oldend = str(end_year_old) + '-', oldstart=str(start_year_old) + '-', \n",
    "                       newend = str(end_year_new) + '-', newstart=str(start_year_new) + '-', include_nao=True\n",
    "                      )\n",
    "\n",
    "        test.prepare_data()  \n",
    "        # Generate example binary time series data for test.old\n",
    "\n",
    "        # Generate example binary time series data for test.new\n",
    "        y_prec_new = (test.new.Temp >= 5) * 1\n",
    "        data_new = pd.DataFrame(y_prec_new, columns=['Temp'])\n",
    "        data_new.columns=['rainy_day']\n",
    "        data_new['nao_index_cdas'] = test.new.nao_index_cdas\n",
    "        data_new['rain_mm'] = test.new.Temp\n",
    "        data_new = data_new[data_new != -9999]\n",
    "        \n",
    "        # Assign season to each row\n",
    "        data_new['season'] = data_new.index.month.isin([12])#data_new.index.month.map(get_season).values\n",
    "        data_winter_new = data_new.loc[(data_new.season == True) & (data_new.index >=pd.Timestamp('2023-03-01'))]\n",
    "        total_precip_acc = data_winter_new['rain_mm'].sum()\n",
    "        \n",
    "        iT = len(data_winter_new)\n",
    "        # Calculate the number of rainy days (rainy_day == 1) in the filtered data\n",
    "        rainy_days_count = data_winter_new['rainy_day'].sum()\n",
    "        # Calculate the percentage of rainy days\n",
    "        if iT > 0:\n",
    "            percentage_rainy_days_total = (rainy_days_count / iT) * 100\n",
    "        else:\n",
    "            percentage_rainy_days_total = 0\n",
    "        \n",
    "        # Filter the rows where nao_index_cdas >= 0.9492\n",
    "        filtered_data = data_winter_new[data_winter_new['nao_index_cdas'] >= 0.9492]\n",
    "        \n",
    "        # Calculate the total number of filtered rows\n",
    "        total_filtered = len(filtered_data)\n",
    "        \n",
    "        # Calculate the number of rainy days (rainy_day == 1) in the filtered data\n",
    "        rainy_days_count = filtered_data['rainy_day'].sum()\n",
    "        nao_upper_quintile_acc = filtered_data['rain_mm'].sum()\n",
    "        # Calculate the percentage of rainy days\n",
    "        if total_filtered > 0:\n",
    "            percentage_rainy_days_upperquintile = (rainy_days_count / total_filtered) * 100\n",
    "        else:\n",
    "            percentage_rainy_days_upperquintile = 0\n",
    "        \n",
    "\n",
    "            \n",
    "        # Filter the rows where nao_index_cdas >= 0.9492\n",
    "        filtered_data = data_winter_new[data_winter_new['nao_index_cdas'] >= 0.]\n",
    "        \n",
    "        # Calculate the total number of filtered rows\n",
    "        total_filtered = len(filtered_data)\n",
    "        \n",
    "        # Calculate the number of rainy days (rainy_day == 1) in the filtered data\n",
    "        rainy_days_count = filtered_data['rainy_day'].sum()\n",
    "        \n",
    "        # Calculate the percentage of rainy days\n",
    "        if total_filtered > 0:\n",
    "            percentage_rainy_days_NAOplus = (rainy_days_count / total_filtered) * 100\n",
    "        else:\n",
    "            percentage_rainy_days_NAOplus = 0\n",
    "        nao_pos_acc = filtered_data['rain_mm'].sum()\n",
    "\n",
    "        # Identify streaks of consecutive ones in the 'Temp' column\n",
    "        data_winter_new.loc[:, 'streak'] = (data_winter_new['rainy_day'] != data_winter_new['rainy_day'].shift()).cumsum()\n",
    "        streaks = data_winter_new[data_winter_new['rainy_day'] == 1].groupby('streak').size()\n",
    "        \n",
    "        # Get the maximum streak of ones\n",
    "        max_streak = streaks.max()\n",
    "        acc_rainfall = np.sum(data_winter_new.rain_mm)\n",
    "        \n",
    "        df_results.iloc[i, :] = [df.city_name.iloc[i], df.STAID.iloc[i], df.latitude.iloc[i], df.longitude.iloc[i], \\\n",
    "                                 max_streak, acc_rainfall, percentage_rainy_days_upperquintile, percentage_rainy_days_NAOplus, \\\n",
    "                                     nao_upper_quintile_acc, nao_pos_acc, total_precip_acc, percentage_rainy_days_total]\n",
    "    except (ValueError, np.linalg.LinAlgError, PerfectSeparationError) as e: \n",
    "        pass \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07331e3c-d610-4c6f-b128-a688f5694d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_fig1 = df_results.dropna().set_index('STANAME')\n",
    "#df_results_fig1 = df_results_fig1.drop(['IZANA','ELAT', 'ELAT-1', 'STA. CRUZ DE TENERIFE', 'TENERIFE/LOS RODEOS'],axis=0)\n",
    "#df_results_fig1.to_csv('/Users/admin/Documents/PhD/persistence/data_persistence/results_precipitation_' + str(start_date) + 'Fig1_dec.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3250b2-94d2-4ebb-a27c-0047d3f3a3b4",
   "metadata": {},
   "source": [
    "## Generate data for Figure 4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1014ba15-b3e6-497e-ac18-9c649cce7af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = 1950\n",
    "start_year_old = start_date\n",
    "end_year_old = start_date + 30\n",
    "start_year_new = 1990\n",
    "end_year_new = start_year_new + 30\n",
    "drop_na_larger_than = 0.05\n",
    "\n",
    "folder_path = '../data_persistence/ECA_blend_rr/'\n",
    "lendata = len(np.sort(os.listdir(folder_path))[:-4])\n",
    "lat_long = pd.DataFrame(np.zeros((lendata, 5)))\n",
    "lat_long[:] = np.nan\n",
    "for (i, file_name) in enumerate(np.sort(os.listdir(folder_path))[1:-4]):\n",
    "    station_name, starting_date = read_climate_data(folder_path + file_name)\n",
    "    city_name, latitude, longitude = map_station_with_city(station_name, folder_path + 'stations.txt')\n",
    "    if type(starting_date) != type(None):\n",
    "        if int(starting_date) <= start_date:\n",
    "                lat_long.iloc[i,:] = [file_name, station_name, latitude, longitude, city_name]\n",
    "\n",
    "df = lat_long.dropna()  \n",
    "df.columns =  ['file_name', 'STAID', 'latitude', 'longitude', 'city_name']\n",
    "df_results = pd.DataFrame(np.zeros((len(df), 12)), columns=['STANAME', 'STAID', 'latitude', 'longitude', \n",
    "                                                            'mean_diff_winter', 'mean_diff_spring', 'mean_diff_summer', 'mean_diff_autumn',\n",
    "                                                            'mean_diff_winter_unc', 'mean_diff_spring_unc', 'mean_diff_summer_unc', 'mean_diff_autumn_unc'])\n",
    "df_results[:] = np.nan\n",
    "for (i, file_name) in enumerate(df.file_name):\n",
    "    print(f'\\rCurrently calculating station {i+1} out of {len(df.file_name)}', end='')\n",
    "    \n",
    "    try:\n",
    "        test = QAR_precipitation(sFile=file_name, dropna=drop_na_larger_than,\n",
    "                       oldend = str(end_year_old) + '-', oldstart=str(start_year_old) + '-', \n",
    "                       newend = str(end_year_new) + '-', newstart=str(start_year_new) + '-', include_nao=True\n",
    "                      )\n",
    "        test.prepare_data()  \n",
    "        # Generate example binary time series data for test.old\n",
    "        y_prec_old = (test.old.Temp >= 5) * 1\n",
    "        data_old = pd.DataFrame(y_prec_old, columns=['Temp'])\n",
    "        data_old['nao_index_cdas'] = test.old.nao_index_cdas\n",
    "        \n",
    "        # Generate example binary time series data for test.new\n",
    "        y_prec_new = (test.new.Temp >= 5) * 1\n",
    "        data_new = pd.DataFrame(y_prec_new, columns=['Temp'])\n",
    "        data_new['nao_index_cdas'] = test.new.nao_index_cdas\n",
    "        \n",
    "        # Assign season to each row\n",
    "        data_old['season'] = data_old.index.month.map(get_season).values\n",
    "        data_new['season'] = data_new.index.month.map(get_season).values\n",
    "        \n",
    "        \n",
    "        data_winter_new, data_winter_old = data_new.loc[data_new.season == 'winter'],  data_old.loc[data_old.season == 'winter']\n",
    "        p_rain_cond_nao_new_winter = data_winter_new.loc[data_winter_new.nao_index_cdas.shift(1) > np.quantile(data_winter_new.nao_index_cdas, .8)].mean().Temp\n",
    "        p_rain_cond_nao_old_winter = data_winter_old.loc[data_winter_old.nao_index_cdas.shift(1) > np.quantile(data_winter_old.nao_index_cdas, .8)].mean().Temp\n",
    "        diff_winter_unc = p_rain_cond_nao_new_winter - p_rain_cond_nao_old_winter\n",
    "\n",
    "        \n",
    "        df_results.iloc[i, :] = [df.city_name.iloc[i], df.STAID.iloc[i], df.latitude.iloc[i], df.longitude.iloc[i], \\\n",
    "                                 diff_winter_unc]\n",
    "    except (ValueError, np.linalg.LinAlgError, PerfectSeparationError) as e: \n",
    "        pass \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f0ef9f-da44-4b07-a36e-18a162635aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_4a = df_results.dropna().set_index('STANAME')\n",
    "#df_results_4a = df_results_4a.drop(['IZANA','ELAT', 'ELAT-1', 'STA. CRUZ DE TENERIFE', 'TENERIFE/LOS RODEOS'],axis=0)\n",
    "#df_results_4a.to_csv('../data_persistence/results_precipitation_' + str(start_date) + 'WithUncProbabilities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b659ecf-d6b7-43ef-94aa-67302765867b",
   "metadata": {},
   "source": [
    "## Generate data for Figure 4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e02517-b4a1-4838-a171-d35c585bbbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_year_old = 1950\n",
    "end_year_old = 1980\n",
    "start_year_new = 1990\n",
    "end_year_new = 2020 \n",
    "drop_na_larger_than = 0.05\n",
    "\n",
    "\n",
    "df = lat_long.dropna()  \n",
    "df.columns =  ['file_name', 'STAID', 'latitude', 'longitude', 'city_name']\n",
    "df_results = pd.DataFrame(np.zeros((len(df), 12)), columns=['STANAME', 'STAID', 'latitude', 'longitude', \n",
    "                                                            'maxStreak', 'rain_acc', 'percentage_rainy_days_upperquintile', 'percentage_rainy_days_NAOplus', \\\n",
    "                                                                'nao_upper_quintile_acc', 'nao_pos_acc', 'total_precip_acc', 'percentage_rainy_days_total'])\n",
    "df_results[:] = np.nan\n",
    "for (i, file_name) in enumerate(df.file_name):\n",
    "    print(f'\\rCurrently calculating station {i+1} out of {len(df.file_name)}', end='')\n",
    "    \n",
    "    try:\n",
    "        test = QAR_precipitation(sFile=file_name, dropna=drop_na_larger_than,\n",
    "                       oldend = str(end_year_old) + '-', oldstart=str(start_year_old) + '-', \n",
    "                       newend = str(end_year_new) + '-', newstart=str(start_year_new) + '-', include_nao=True\n",
    "                      )\n",
    "\n",
    "        test.prepare_data()  \n",
    "        # Generate example binary time series data for test.old\n",
    "\n",
    "        # Generate example binary time series data for test.new\n",
    "        y_prec_new = (test.new.Temp >= 5) * 1\n",
    "        data_new = pd.DataFrame(y_prec_new, columns=['Temp'])\n",
    "        data_new.columns=['rainy_day']\n",
    "        data_new['nao_index_cdas'] = test.new.nao_index_cdas\n",
    "        data_new['rain_mm'] = test.new.Temp\n",
    "        data_new = data_new[data_new != -9999]\n",
    "        \n",
    "        # Assign season to each row\n",
    "        data_new['season'] = data_new.index.month.map(get_season).values\n",
    "        data_winter_new = data_new.loc[(data_new.season == 'winter')]\n",
    "        total_precip_acc = data_winter_new['rain_mm'].sum()\n",
    "        \n",
    "        iT = len(data_winter_new)\n",
    "        # Calculate the number of rainy days (rainy_day == 1) in the filtered data\n",
    "        rainy_days_count = data_winter_new['rainy_day'].sum()\n",
    "        # Calculate the percentage of rainy days\n",
    "        if iT > 0:\n",
    "            percentage_rainy_days_total = (rainy_days_count / iT) * 100\n",
    "        else:\n",
    "            percentage_rainy_days_total = 0\n",
    "        \n",
    "        # Filter the rows where nao_index_cdas >= 0.9492\n",
    "        filtered_data = data_winter_new[data_winter_new['nao_index_cdas'] >= 0.9492]\n",
    "        \n",
    "        # Calculate the total number of filtered rows\n",
    "        total_filtered = len(filtered_data)\n",
    "        \n",
    "        # Calculate the number of rainy days (rainy_day == 1) in the filtered data\n",
    "        rainy_days_count = filtered_data['rainy_day'].sum()\n",
    "        nao_upper_quintile_acc = filtered_data['rain_mm'].sum()\n",
    "        # Calculate the percentage of rainy days\n",
    "        if total_filtered > 0:\n",
    "            percentage_rainy_days_upperquintile = (rainy_days_count / total_filtered) * 100\n",
    "        else:\n",
    "            percentage_rainy_days_upperquintile = 0\n",
    "        \n",
    "\n",
    "            \n",
    "        # Filter the rows where nao_index_cdas >= 0.9492\n",
    "        filtered_data = data_winter_new[data_winter_new['nao_index_cdas'] >= 0.]\n",
    "        \n",
    "        # Calculate the total number of filtered rows\n",
    "        total_filtered = len(filtered_data)\n",
    "        \n",
    "        # Calculate the number of rainy days (rainy_day == 1) in the filtered data\n",
    "        rainy_days_count = filtered_data['rainy_day'].sum()\n",
    "        \n",
    "        # Calculate the percentage of rainy days\n",
    "        if total_filtered > 0:\n",
    "            percentage_rainy_days_NAOplus = (rainy_days_count / total_filtered) * 100\n",
    "        else:\n",
    "            percentage_rainy_days_NAOplus = 0\n",
    "        nao_pos_acc = filtered_data['rain_mm'].sum()\n",
    "\n",
    "        # Identify streaks of consecutive ones in the 'Temp' column\n",
    "        data_winter_new.loc[:, 'streak'] = (data_winter_new['rainy_day'] != data_winter_new['rainy_day'].shift()).cumsum()\n",
    "        streaks = data_winter_new[data_winter_new['rainy_day'] == 1].groupby('streak').size()\n",
    "        \n",
    "        # Get the maximum streak of ones\n",
    "        max_streak = streaks.max()\n",
    "        acc_rainfall = np.sum(data_winter_new.rain_mm)\n",
    "        \n",
    "        df_results.iloc[i, :] = [df.city_name.iloc[i], df.STAID.iloc[i], df.latitude.iloc[i], df.longitude.iloc[i], \\\n",
    "                                 max_streak, acc_rainfall, percentage_rainy_days_upperquintile, percentage_rainy_days_NAOplus, \\\n",
    "                                     nao_upper_quintile_acc, nao_pos_acc, total_precip_acc, percentage_rainy_days_total]\n",
    "    except (ValueError, np.linalg.LinAlgError, PerfectSeparationError) as e: \n",
    "        pass \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb63b370-0aba-4c5e-98ef-01b44a254c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_4b = df_results.dropna().set_index('STANAME')\n",
    "#df_results_4b = df_results_4b.drop(['IZANA','ELAT', 'ELAT-1', 'STA. CRUZ DE TENERIFE', 'TENERIFE/LOS RODEOS'],axis=0)\n",
    "#df_results_4b.to_csv('../data_persistence/results_precipitation_1950WithUncProbabilities.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
